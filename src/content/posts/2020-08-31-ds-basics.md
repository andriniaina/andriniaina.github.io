---
title: "Data science basics"
date: 2020-08-31T12:36:40+02:00
draft: false
toc: false
images:
tags:
  - data science
  - python
  - pytorch
  - tensorflow
---

Exploring data
===

Analyse distribution
---

1. `df['Grade'].describe()`: if mean==median, then try normal distribution
2. vizualize distribution: `plt.hist(df['Grade'])` & `plt.boxplot(df['Grade'], vert=False)`
3. `df_students['Grade']` : directly compute density graph (smoothed distribution)

Regression
===

1. for each dimension: analyse distribution, draw histograms, boxplots
1. clean NaN data: `.isnull()`
1. use sklearn.pipeline.Pipeline to 
    * normalize, e.g. `StandardScaler()`
    * encode categorical data: `OneHotEncoder()`
2. compute correlation of dimension vs feature
    * pandas corr(): `bike_data[dimension].corr(bike_data[feature])`
    * vizualise possible linear correlation: `plt.scatter(x=feature,  y=label)`
    * for a given dimension, display boxplot for each dimension value:
    ```py
    for col in categorical_features:
     fig = plt.figure(figsize=(9, 6))
     ax = fig.gca()
     df.boxplot(column = 'rentals', by = col, ax = ax)
    ```
3. split training and test (validation) data: `X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=0)`
4. `model = LinearRegression(normalize=False).fit(X_train, y_train); model.predict()`: note that normalize=False because data should have been already normalized
5. validate model
    * plot actual vs predictions: `plt.scatter(y_test, predictions`
    * plot actual vs predictions theretical regression line `np.poly1d(np.polyfit(y_test, predictions, 1))`
    * metrics: `np.sqrt(mean_squared_error(y_test, predictions))` & `r2_score(y_test, predictions)`
6. save model for future exectution: `joblib.dump(model, filename); joblib.load(filename).predict()`

Binary Classification
===

**Exactly** same as above but with `model = LogisticRegression(C=1/reg, solver="liblinear").fit(X_train, y_train)` reg=0.01 being the learning rate.

But you really should try `RandomForestClassifier()`

And then validate:
1. `sklearn.metrics.classification_report(y_test, predictions)`
    ```
               precision    recall  f1-score   support

       class0       0.81      0.88      0.85      2986
       class1       0.72      0.60      0.66      1514

   micro avg       0.79      0.79      0.79      4500
   macro avg       0.77      0.74      0.75      4500
   weighted avg       0.78      0.79      0.78      4500
    ```
    or `from sklearn.metrics import precision_score, recall_score`
2. `sklearn.metrics.confusion_matrix(y_test, predictions)`.
   Recall=TP/(TP+FN)  and  Precision=TP/(TP+FP)
3. further analysis, get score for each class: `y_scores = model.predict_proba(X_test)`
4. received operator characteristic (ROC) chart: 
    ```py
    false_positive_rate, true_positive_rate, thresholds = sklearn.metrics.roc_curve(y_test, y_scores[:,1])  # ROC for class1
    plt.plot([0, 1], [0, 1], 'k--')  # draw straight line
    plt.plot(false_positive_rate, true_positive_rate)  # draw ROC
    ```
    ROC should e 
5. `sklearn.metrics.roc_auc_score(y_test,y_scores[:,1])`: 0.5 < AUC < 1 . 0.5 being a random coin toss for a binary classification

Multiclass classification
===
Most sklearn algorithms inherently support multiclass. Maybe use Support Vector Machine `from sklearn.svm import SVC`.

So, do everything above and then validate:

```py
mcm = sklearn.metrics.confusion_matrix(y_penguin_test, penguin_predictions)
plt.imshow(mcm, interpolation="nearest", cmap=plt.cm.Blues)
```

Clustering
===

using KMeans
---
KMeans is scalable

1. Normalize, Reduce and Visualize if data can be clustered:
```py
# Normalize the numeric features so they're on the same scale
penguin_features[penguins.columns[0:4]] = MinMaxScaler().fit_transform(penguin_features[penguins.columns[0:4]])
# Reduce dimensions in order to get 2 principal dimensions
pca = PCA(n_components=2).fit(penguin_features.values)
penguins_2d = pca.transform(penguin_features.values)
plt.scatter(penguins_2d[:,0],penguins_2d[:,1])
```
2. find optimal cluster count (tightness). Calculate *within cluster sum of squares* (WCSS):
```py
for i in range(1, 11):
    algo = KMeans(n_clusters = i)
    KMeans(n_clusters=i).fit(penguin_features.values)
    wcss.append(algo.inertia_)
plt.plot(range(1, 11), wcss)
```
3. create model: `KMeans(n_clusters=3, init='k-means++', n_init=20, max_iter=200).fit_predict(penguin_features.values)`
4. validate:
    * plot predictions: `plt.scatter(color=)`

Agglometarive or destructive clustering
---
agglomerative: group nearest pairs and then group again until n_clusters is reached. see `AgglomerativeClustering`

Deep learning
===
deep learning: given a known input vector X and a known output vector Y, guess f where f(X,w,b)=Y ; and where w=node_weights and b=node_bias.

PyTorch
---
see [https://github.com/MicrosoftDocs/ml-basics](https://github.com/MicrosoftDocs/ml-basics)

1. As usual, start by cleaning+normalizing the data
2. train in batches (pick the correct size!)
    ```py
    # Number of hidden layer nodes
    hl = 10
    
    # Define the neural network
    class PenguinNet(nn.Module):
        def __init__(self):
            super(PenguinNet, self).__init__()
            self.fc1 = nn.Linear(len(features), hl)
            self.fc2 = nn.Linear(hl, hl)
            self.fc3 = nn.Linear(hl, len(penguin_classes))
    
        def forward(self, x):
            x = torch.relu(self.fc1(x))
            x = torch.relu(self.fc2(x))
            x = torch.softmax(self.fc3(x),dim=1)
            return x
    
    # Create a model instance from the network
    model = PenguinNet()

    def train(model, data_loader, optimizer):
        # Set the model to training mode
        model.train()
        train_loss = 0
        
        for batch, tensor in enumerate(data_loader):
            data, target = tensor
            #feedforward
            optimizer.zero_grad()
            out = model(data)
            loss = loss_criteria(out, target)
            train_loss += loss.item()
    
            # backpropagate
            loss.backward()
            optimizer.step()
    
        #Return average loss
        avg_loss = train_loss / (batch+1)
        print('Training set: Average loss: {:.6f}'.format(avg_loss))
        return avg_loss
               
                
    def test(model, data_loader):
        # Switch the model to evaluation mode (so we don't backpropagate)
        model.eval()
        test_loss = 0
        correct = 0
    
        with torch.no_grad():
            batch_count = 0
            for batch, tensor in enumerate(data_loader):
                batch_count += 1
                data, target = tensor
                # Get the predictions
                out = model(data)
    
                # calculate the loss
                test_loss += loss_criteria(out, target).item()
    
                # Calculate the accuracy
                _, predicted = torch.max(out.data, 1)
                correct += torch.sum(target==predicted).item()
                
        # Calculate the average loss and total accuracy for this epoch
        avg_loss = test_loss/batch_count
        print('Validation set: Average loss: {:.6f}, Accuracy: {}/{} ({:.0f}%)    \n'.format(
            avg_loss, correct, len(data_loader.dataset),
            100. * correct / len(data_loader.dataset)))
        
        # return average loss for the epoch
        return avg_loss


    # Specify the loss criteria (CrossEntropyLoss for multi-class     classification)
    loss_criteria = nn.CrossEntropyLoss()
    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
    optimizer.zero_grad()
    for epoch in 15:
        # Feed training data into the model to optimize the weights
        train_loss = train(model, train_loader, optimizer)
        # Feed the test data into the model to check its performance
        test_loss = test(model, test_loader)
        training_loss.append(train_loss)
        validation_loss.append(test_loss)
    ```
2. validate: The loss (difference between actual vs predicted values) must be minimal after a few epochs
    ```
    plt.plot(epoch_nums, training_loss)
    plt.plot(epoch_nums, validation_loss)
    ```
3. draw confusion matrix

Tensorflow
---

same as above

```py
import tensorflow
from tensorflow import keras
from tensorflow.keras import models
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense
from tensorflow.keras import utils
from tensorflow.keras import optimizers

# Set random seed for reproducability
tensorflow.random.set_seed(0)
# Set data types for float features
x_train = x_train.astype('float32')
x_test = x_test.astype('float32')

# Set data types for categorical labels
y_train = utils.to_categorical(y_train)
y_test = utils.to_categorical(y_test)

hl = 10 # Number of hidden layer nodes
model = Sequential()
model.add(Dense(hl, input_dim=len(features), activation='relu'))
model.add(Dense(hl, input_dim=hl, activation='relu'))
model.add(Dense(len(penguin_classes), input_dim=hl, activation='softmax'))

learning_rate = 0.001
opt = optimizers.Adam(lr=learning_rate)

model.compile(loss='categorical_crossentropy',
              optimizer=opt,
              metrics=['accuracy'])

# Train the model over 50 epochs using 10-observation batches and using the test holdout dataset for validation
num_epochs = 50
history = model.fit(x_train, y_train, epochs=num_epochs, batch_size=10, validation_data=(x_test, y_test))

training_loss = history.history["loss"]
validation_loss = history.history["val_loss"]
plt.plot(epoch_nums, training_loss)
plt.plot(epoch_nums, validation_loss)
```

Notes: cheatsheet
===
Download the cheat sheet here: [Machine Learning Algorithm Cheat Sheet](https://download.microsoft.com/download/3/5/b/35bb997f-a8c7-485d-8c56-19444dafd757/azure-machine-learning-algorithm-cheat-sheet-nov2019.pdf?WT.mc_id=docs-article-lazzeri)

Notes: Pandas/Numpy basics
===
```py
df_students.iloc[0:5]  #get first rows 0 to 4 included
df_students.loc[0,'Grade']  # get cell
df_students.loc[df_students['Name']=='Aisha']  # filter
df_students.plot.bar(x='Name', y='StudyHours', color='teal', figsize=(6,4))  # directly display a histogram without having to deal with graphing libraries

%matplotlib inline
from matplotlib import pyplot as plt
plt.bar(x=df_students.Name, height=df_students.Grade)
d=df_students['Pass'].value_counts(); plt.pie(d, labels=d)
plt.hist(df_students['Grade'])
```
